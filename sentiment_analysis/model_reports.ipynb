{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Linh Van NGUYEN\n",
    "\n",
    "Date: 16/5/2016\n",
    "\n",
    "### Requirements:\n",
    "    * sklearn\n",
    "    * pandas\n",
    "    * xgboost\n",
    "    * BeautifulSoup\n",
    "    * nltk\n",
    "To install the required package, run this command in the terminal:\n",
    "    \n",
    "    sudo pip install -r requirements.txt\n",
    "\n",
    "Also two following files should be in the same directory:\n",
    "    * utils.py - some useful functions\n",
    "        read_textfile(filename, separate): read text from file with given separator\n",
    "        score_model(model,X,t,cv,scoring): return score of a classifier using cross-validation\n",
    "        text_to_wordlist(text, remove_stopwords=False): clean and return wordlist from given tweets\n",
    "    * predict_sentiments.py - function to predict sentiments from given tweets\n",
    "        predict_singlemodel(tweetsTrain, labelsTrain, tweetsTest): using the best single model \n",
    "        predict_singlemodel(tweetsTrain, labelsTrain, tweetsTest): ensemble all models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "\n",
    "import utils as utils\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn import svm, cross_validation\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the data\n",
    "To start, it is important to look at the data: the fields, size, data type ...\n",
    "The data given is 6588 tweets of different subjects, classified into 3 categories of sentiments: *positive*, *neural* and *negative*. The problem is to learn from these training samples and propose models that can predict a given tweets to see the sentiment of the person who posted it. \n",
    "\n",
    "Data is given in text file. It is more convenient to work with panda dataframe sometime. Sentiments are also converted to 0, 1, 2 for positive, neutral and negative respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = utils.read_textfile('train-tweets.txt',',')\n",
    "tweets = df.tweet.values\n",
    "labels = pd.factorize(df.sentiment)[0]\n",
    "sentiments = pd.factorize(df.sentiment)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of tweets:', 6588)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit, watch Rafa and Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I'm a GSP fan, i just hate Nick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Pola...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                              tweet\n",
       "0  positive   Gas by my house hit $3.39!!!! I'm going to Ch...\n",
       "1  negative   Theo Walcott is still shit, watch Rafa and Jo...\n",
       "2  negative   its not that I'm a GSP fan, i just hate Nick ...\n",
       "3  negative   Iranian general says Israel's Iron Dome can't...\n",
       "4  positive   with J Davlar 11th. Main rivals are team Pola..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total number of tweets:',len(tweets))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text and extract words\n",
    "The original tweets are cleaned to make everything lower case, remove non-letter characters, and remove links. After the cleaning, the function returns a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tweet: Most common nights to order pizza: NYE, Jan 1, day before Thanksgiving, Super Bowl Sunday, Halloween. http://p-bu.mp/msp-Â \n",
      "\n",
      "Cleaned tweet:common nights order pizza nye jan day thanksgiving super bowl sunday halloween\n"
     ]
    }
   ],
   "source": [
    "print('Sample tweet:%s' % (tweets[100]))\n",
    "print('Cleaned tweet:%s' % (' '.join(utils.text_to_wordlist(tweets[100], True))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features\n",
    "To build machine learning models for natural language, it is essential to convert text into numeric features. The most common way is to use *Bag-of-word*, which creates a huge sparse matrix of all possible words in the text, then counting the number of each appearance. Another way is *Term-frequency*, which is to normalized version *Bag-of-word*. The *Term Frequency times Inverse Document Frequency* takes into account the words appears many times, which in fact less informative and therefore should take less weights. Further information can be found here:\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "Other vectorization such as *Word2Vec* can be studied as well.\n",
    "\n",
    "In this code, I investigated 3 different ways of vectorization: *Bag-of-word*, *Term Frequency times Inverse Document Frequency*, and stacking version of these two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0]\n",
      " [1 1 1 0 1]]\n",
      "[[ 0.5  0.5  0.5  0.5  0. ]\n",
      " [ 0.5  0.5  0.5  0.   0.5]]\n"
     ]
    }
   ],
   "source": [
    "print CountVectorizer().fit_transform([\"Hello Pierre, I am Linh\", \"Hello Linh, I am Sylvian\"]).A\n",
    "print TfidfVectorizer(use_idf=False).fit_transform([\"Hello Pierre, I am Linh\", \"Hello Linh, I am Sylvian\"]).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words,which is less informative:\n",
      "1769 and\n",
      "1333 at\n",
      "1569 for\n",
      "2093 in\n",
      "1273 is\n",
      "1664 of\n",
      "2041 on\n",
      "5736 the\n",
      "3030 to\n",
      "1149 with\n"
     ]
    }
   ],
   "source": [
    "# join all tweets into one text\n",
    "texts = []\n",
    "for tweet in tweets:\n",
    "    texts.append(\" \".join(utils.text_to_wordlist(tweet, False)))\n",
    "    \n",
    "# Vectorizing\n",
    "maxFeatures = 10\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = None,\n",
    "    lowercase = True,\n",
    "    stop_words = None,\n",
    "    max_features = maxFeatures\n",
    ")\n",
    "\n",
    "sampleFeatures = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "dist = np.sum(sampleFeatures, axis=0)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "print \"Top 10 most frequent words,which is less informative:\"\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.70336456  0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.56616306 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing\n",
    "maxFeatures = 10\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=maxFeatures, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "sampleFeatures = tfv.fit_transform(texts).toarray()\n",
    "print sampleFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Various classifiers\n",
    "Here I investigate the standard classifiers, from naive Bayes, logistic classification, linear SVM to various ensembled version of decision tree such as Random Forest, Extra Tree, ADA boost and very new (and powerful) extreme gradient boosting from *xgboost* package\n",
    "\n",
    "Model selection and parameter optimization are done using standard k-fold cross validation (stratified version, which equally split the labels) for all three cases of vectorization:\n",
    "    \n",
    "    *cross_validataion_CountVectorizer.py: \"bag-of-word\"\n",
    "    *cross_validataion_TfidfVectorizer.py: \"Term Frequency times Inverse Document Frequency\"\n",
    "    *cross_validataion_CountTfidfVectorizer.py: using joined (stacked) features from the above two\n",
    "\n",
    "Accuracy of each classifiers are reported for 3 different cases averaging from 10 folds of cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag-of-word: feature vectorized by counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxFeatures = 2000\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = None,\n",
    "    lowercase = True,\n",
    "    stop_words = None,\n",
    "    max_features = maxFeatures\n",
    ")\n",
    "      \n",
    "featuresCountVectorized = vectorizer.fit_transform(texts)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ( LR): 0.666819\n",
      "Accuracy ( NB): 0.634183\n",
      "Accuracy (SVM): 0.669393\n",
      "Accuracy ( RF): 0.668183\n",
      "Accuracy (EXT): 0.678805\n",
      "Accuracy (ADA): 0.667264\n",
      "Accuracy (XGB): 0.684417\n"
     ]
    }
   ],
   "source": [
    "skfCV = cross_validation.StratifiedKFold(labels, n_folds=10, shuffle=True, random_state=None) # split target equally\n",
    "\n",
    "clfLR = LogisticRegression(penalty='l2', dual=True, tol=0.0001, C=1, fit_intercept=True, \n",
    "                           intercept_scaling=1.0, class_weight=None, random_state=None)\n",
    "clfNB = MultinomialNB()\n",
    "clfSGD = SGDClassifier(loss='hinge', penalty='l2', alpha = 3*1e-3, n_iter=5, random_state=42)\n",
    "clfRF = RandomForestClassifier(n_estimators=250)\n",
    "clfEXT = ExtraTreesClassifier(n_estimators=300)\n",
    "clfADA = AdaBoostClassifier(n_estimators=100, learning_rate = 0.75)\n",
    "clfXGB = xgb.XGBClassifier(objective= 'logistic', nthread=3, silent = 1, seed=8,\n",
    "                           n_estimators = 400, max_depth = 6, learning_rate = 0.075, \n",
    "                           subsample = 0.9, colsample_bytree = 1.0)\n",
    "\n",
    "print(\"Accuracy ( LR): %f\" % (np.mean(utils.score_model(clfLR ,featuresCountVectorized,labels, \n",
    "                                                        cv = skfCV, scoring = \"accuracy\"))))\n",
    "print(\"Accuracy ( NB): %f\" % ( np.mean(utils.score_model(clfNB ,featuresCountVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (SVM): %f\" % ( np.mean(utils.score_model(clfSGD,featuresCountVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy ( RF): %f\" % ( np.mean(utils.score_model(clfRF ,featuresCountVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (EXT): %f\" % ( np.mean(utils.score_model(clfEXT,featuresCountVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (ADA): %f\" % ( np.mean(utils.score_model(clfADA,featuresCountVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (XGB): %f\" % ( np.mean(utils.score_model(clfXGB,featuresCountVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Term Frequency times Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxFeatures = 2000\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=maxFeatures, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "featuresVectorized = tfv.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ( LR): 0.671982\n",
      "Accuracy ( NB): 0.639040\n",
      "Accuracy (SVM): 0.675166\n",
      "Accuracy ( RF): 0.673037\n",
      "Accuracy (EXT): 0.675926\n",
      "Accuracy (ADA): 0.667582\n",
      "Accuracy (XGB): 0.680325\n"
     ]
    }
   ],
   "source": [
    "skfCV = cross_validation.StratifiedKFold(labels, n_folds=10, shuffle=True, random_state=None) # split target equally\n",
    "\n",
    "clfLR = LogisticRegression(penalty='l2', dual=True, tol=0.0001, C=1, fit_intercept=True, \n",
    "                           intercept_scaling=1.0, class_weight=None, random_state=None)\n",
    "clfNB = MultinomialNB()\n",
    "clfSGD = SGDClassifier(loss='hinge', penalty='l2', alpha = 3*1e-4, n_iter=5, random_state=42)\n",
    "clfRF = RandomForestClassifier(n_estimators=250)\n",
    "clfEXT = ExtraTreesClassifier(n_estimators=300)\n",
    "clfADA = AdaBoostClassifier(n_estimators=100, learning_rate = 0.75)\n",
    "clfXGB = xgb.XGBClassifier(objective= 'logistic', nthread=3, silent = 1, seed=8,\n",
    "                           n_estimators = 400, max_depth = 6, learning_rate = 0.075, \n",
    "                           subsample = 0.9, colsample_bytree = 1.0)\n",
    "\n",
    "print(\"Accuracy ( LR): %f\" % (np.mean(utils.score_model(clfLR ,featuresVectorized,labels, \n",
    "                                                        cv = skfCV, scoring = \"accuracy\"))))\n",
    "print(\"Accuracy ( NB): %f\" % ( np.mean(utils.score_model(clfNB,featuresVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (SVM): %f\" % ( np.mean(utils.score_model(clfSGD,featuresVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy ( RF): %f\" % ( np.mean(utils.score_model(clfRF,featuresVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (EXT): %f\" % ( np.mean(utils.score_model(clfEXT,featuresVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (ADA): %f\" % ( np.mean(utils.score_model(clfADA,featuresVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (XGB): %f\" % ( np.mean(utils.score_model(clfXGB,featuresVectorized,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Joined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ( LR): 0.665611\n",
      "Accuracy ( NB): 0.632985\n",
      "Accuracy (SVM): 0.665611\n",
      "Accuracy ( RF): 0.680329\n",
      "Accuracy (EXT): 0.681552\n",
      "Accuracy (ADA): 0.661061\n",
      "Accuracy (XGB): 0.677758\n"
     ]
    }
   ],
   "source": [
    "featuresStacked = scipy.sparse.hstack([featuresVectorized, featuresCountVectorized])\n",
    "skfCV = cross_validation.StratifiedKFold(labels, n_folds=10, shuffle=True, random_state=None) # split target equally\n",
    "\n",
    "clfLR = LogisticRegression(penalty='l2', dual=True, tol=0.0001, C=1, fit_intercept=True, \n",
    "                           intercept_scaling=1.0, class_weight=None, random_state=None)\n",
    "clfNB = MultinomialNB()\n",
    "clfSGD = SGDClassifier(loss='hinge', penalty='l2', alpha = 3*1e-3, n_iter=5, random_state=42)\n",
    "clfRF = RandomForestClassifier(n_estimators=250)\n",
    "clfEXT = ExtraTreesClassifier(n_estimators=300)\n",
    "clfADA = AdaBoostClassifier(n_estimators=100, learning_rate = 0.75)\n",
    "clfXGB = xgb.XGBClassifier(objective= 'logistic', nthread=3, silent = 1, seed=8,\n",
    "                           n_estimators = 400, max_depth = 6, learning_rate = 0.075, \n",
    "                           subsample = 0.9, colsample_bytree = 1.0)\n",
    "\n",
    "print(\"Accuracy ( LR): %f\" % (np.mean(utils.score_model(clfLR ,featuresStacked,labels, \n",
    "                                                        cv = skfCV, scoring = \"accuracy\"))))\n",
    "print(\"Accuracy ( NB): %f\" % ( np.mean(utils.score_model(clfNB ,featuresStacked,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (SVM): %f\" % ( np.mean(utils.score_model(clfSGD,featuresStacked,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy ( RF): %f\" % ( np.mean(utils.score_model(clfRF ,featuresStacked,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (EXT): %f\" % ( np.mean(utils.score_model(clfEXT,featuresStacked,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (ADA): %f\" % ( np.mean(utils.score_model(clfADA,featuresStacked,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))\n",
    "print(\"Accuracy (XGB): %f\" % ( np.mean(utils.score_model(clfXGB,featuresStacked,labels, \n",
    "                                                         cv = skfCV,scoring = \"accuracy\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Detailed model reports (precision, recall, f1-score)\n",
    "This part shows detailed report of each classifiers by virtually spliting the training sample into training and testing data. Models are reported using *precision*, *recall* and *f1-score*\n",
    "\n",
    "*Precision*:  true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p$). i.e. $$P = \\frac{T_p}{T_p+F_p}$$\n",
    "\n",
    "*Recall*: the number of true positives $T_p$ over the number of true positives plus the number of false negatives $F_n$, i.e. $$R = \\frac{T_p}{T_p+F_n}$$\n",
    "\n",
    "*F1-score* is the harmonic mean of precision and recall: $$F1 = \\frac{2PR}{P+R}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresTrain, featuresTest, labelsTrain, labelsTest = cross_validation.train_test_split(featuresStacked, labels, \n",
    "                                                                      train_size=0.85, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.64      0.66       354\n",
      "          1       0.48      0.27      0.35       157\n",
      "          2       0.65      0.78      0.71       478\n",
      "\n",
      "avg / total       0.64      0.65      0.64       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfLR = LogisticRegression(penalty='l2', dual=True, tol=0.0001, C=1, fit_intercept=True, \n",
    "                           intercept_scaling=1.0, class_weight=None, random_state=None)\n",
    "clfLR = clfLR.fit(X=featuresTrain, y=labelsTrain)\n",
    "labelsPred = clfLR.predict(featuresTest)\n",
    "print(classification_report(labelsTest, labelsPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.70      0.66       354\n",
      "          1       0.50      0.41      0.45       157\n",
      "          2       0.69      0.67      0.68       478\n",
      "\n",
      "avg / total       0.64      0.64      0.64       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfNB = MultinomialNB()\n",
    "clfNB = clfNB.fit(X=featuresTrain, y=labelsTrain)\n",
    "labelsPred = clfNB.predict(featuresTest)\n",
    "print(classification_report(labelsTest, labelsPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machine (linear kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.54      0.62       354\n",
      "          1       0.52      0.21      0.30       157\n",
      "          2       0.62      0.87      0.73       478\n",
      "\n",
      "avg / total       0.65      0.65      0.62       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfSGD = SGDClassifier(loss='hinge', penalty='l2', alpha = 3*1e-3, n_iter=5, random_state=42)\n",
    "clfSGD = clfSGD.fit(X=featuresTrain, y=labelsTrain)\n",
    "labelsPred = clfSGD.predict(featuresTest)\n",
    "print(classification_report(labelsTest, labelsPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.56      0.64       354\n",
      "          1       0.60      0.17      0.27       157\n",
      "          2       0.63      0.90      0.74       478\n",
      "\n",
      "avg / total       0.67      0.66      0.63       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(n_estimators=250)\n",
    "clfRF.fit(X=featuresTrain, y=labelsTrain)\n",
    "labelsPred = clfRF.predict(featuresTest)\n",
    "print(classification_report(labelsTest, labelsPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.61      0.67       354\n",
      "          1       0.59      0.21      0.31       157\n",
      "          2       0.65      0.86      0.74       478\n",
      "\n",
      "avg / total       0.67      0.67      0.64       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfEXT = ExtraTreesClassifier(n_estimators=300)\n",
    "clfEXT.fit(X=featuresTrain, y=labelsTrain)\n",
    "labelsPred = clfEXT.predict(featuresTest)\n",
    "print(classification_report(labelsTest, labelsPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.56      0.64       354\n",
      "          1       0.60      0.25      0.35       157\n",
      "          2       0.65      0.90      0.75       478\n",
      "\n",
      "avg / total       0.68      0.67      0.65       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfXGB = xgb.XGBClassifier(objective= 'logistic', nthread=3, silent = 1, seed=8,\n",
    "                           n_estimators = 400, max_depth = 6, learning_rate = 0.075, \n",
    "                           subsample = 0.9, colsample_bytree = 1.0)\n",
    "clfXGB.fit(X=featuresTrain, y=labelsTrain)\n",
    "labelsPred = clfXGB.predict(featuresTest)\n",
    "print(classification_report(labelsTest, labelsPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features significance\n",
    "It is noticed that many words bring no value to help predicting sentiments. Others like adjectives do help much more. For this reason, it is beneficial to keep only significant features. They are selected from random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 897)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0189366ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(n_estimators=250)\n",
    "clfRF = clfRF.fit(X=featuresTrain, y=labelsTrain)\n",
    "\n",
    "plt.plot(clfRF.feature_importances_)\n",
    "\n",
    "model = SelectFromModel(clfRF, \"1.0*mean\", prefit=True)\n",
    "featuresTrainSel = model.transform(featuresTrain)\n",
    "featuresTestSel = model.transform(featuresTest)\n",
    "featuresTestSel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.75      0.68       298\n",
      "          1       0.26      0.53      0.35        77\n",
      "          2       0.85      0.66      0.74       614\n",
      "\n",
      "avg / total       0.73      0.68      0.69       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfLR = LogisticRegression(penalty='l2', dual=True, tol=0.0001, C=1, fit_intercept=True, \n",
    "                           intercept_scaling=1.0, class_weight=None, random_state=None)\n",
    "clfLR = clfLR.fit(X=featuresTrainSel, y=labelsTrain)\n",
    "labelsPred = clfLR.predict(featuresTestSel)\n",
    "print(classification_report(labelsPred, labelsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.76      0.61       237\n",
      "          1       0.20      0.58      0.30        53\n",
      "          2       0.90      0.61      0.73       699\n",
      "\n",
      "avg / total       0.77      0.65      0.68       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfSGD = SGDClassifier(loss='hinge', penalty='l2', alpha = 3*1e-3, n_iter=5, random_state=42)\n",
    "clfSGD = clfSGD.fit(X=featuresTrainSel, y=labelsTrain)\n",
    "labelsPred = clfSGD.predict(featuresTestSel)\n",
    "print(classification_report(labelsPred, labelsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 4: Ensemble all models\n",
    " As discussed by Pedro Domigos (who gives one of my favorist ML course) in his paper: http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf, it is not about which algorithm is the best, but more about who has more data. Since the data in this example is fixed, it is the question of combining many models. Also, take a closer look at the results of precision and recall for each classifier, their behaviors are rather different. It is a good sign for ensembling where different models can be combined to give better prediction.\n",
    " \n",
    "The simpliest ensemble method is averaging. Here I ensemble the prediction of 16 models presented above by simple averaging. More sophisticated approach such as stacking can be also used. \n",
    " \n",
    "By this simple ensemble of 16 models, results are improved significantly compared to single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Cleaning text \n",
      "\n",
      "Step 2: Extracting features \n",
      "\n",
      "Step 3: Training classifiers \n",
      "\n",
      "For vectorized features ....\n",
      "counting features ....\n",
      "stacked features ....\n",
      "and significant features ....\n",
      "done! \n",
      "\n",
      "Final predictions and ensemble \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.75      0.67       280\n",
      "          1       0.23      0.63      0.34        57\n",
      "          2       0.88      0.64      0.74       652\n",
      "\n",
      "avg / total       0.76      0.67      0.70       989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetsTrain, tweetsTest, labelsTrain, labelsTest = cross_validation.train_test_split(tweets, labels, \n",
    "                                                                      train_size=0.85, random_state=1234)\n",
    "import predict_sentiments as ps\n",
    "labelsPred = ps.predict_ensemblemodels(tweetsTrain, labelsTrain, tweetsTest)\n",
    "print(classification_report(labelsPred, labelsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Future works\n",
    "There are still many interesting things to try:\n",
    "    \n",
    "    * Deep learning using Recurrent Neural Network: I have tried a bit for this data, but results are not satisfactory. The reason is the size of training samples, which is rather limitted in this example. Also, the topic in the given tweets is varied significantly, also required the amount of training data very large.\n",
    "    \n",
    "    * Other ideas such as NBSVM or Paragraph Vector\n",
    "    \n",
    "    * More complicated ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

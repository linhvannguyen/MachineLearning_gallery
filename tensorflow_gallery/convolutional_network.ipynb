{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import input_data # defined function to load data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import MINST data\n",
    "This data contains 3 sets: training set (*mnist.train*) of 55000 samples, validation set (*mnist.validation*) of 5000 samples, and testing set (*mnist.test*) of 10000 samples. In each set, one sample contains an image of size 784 (28x28), a label of size 10 (all zeros except one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(5000, 10)\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAADTCAYAAABOQ5KuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8549dce890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print np.shape(mnist.train.images)\n",
    "print np.shape(mnist.validation.labels)\n",
    "print mnist.test.num_examples\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.reshape(mnist.train.images[i],(28,28)), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv2d(img, w, b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, 1, 1, 1], padding='SAME'),b))\n",
    "\n",
    "def max_pool(img, k):\n",
    "    return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def conv_net(_X, _weights, _biases, _dropout):\n",
    "    # Reshape input picture\n",
    "    _X = tf.reshape(_X, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(_X, _weights['wc1'], _biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = max_pool(conv1, k=2)\n",
    "    # Apply Dropout\n",
    "    conv1 = tf.nn.dropout(conv1, _dropout)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, _weights['wc2'], _biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = max_pool(conv2, k=2)\n",
    "    # Apply Dropout\n",
    "    conv2 = tf.nn.dropout(conv2, _dropout)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit dense layer input\n",
    "    dense1 = tf.reshape(conv2, [-1, _weights['wd1'].get_shape().as_list()[0]]) \n",
    "    # Relu activation\n",
    "    dense1 = tf.nn.relu(tf.add(tf.matmul(dense1, _weights['wd1']), _biases['bd1']))\n",
    "    # Apply Dropout\n",
    "    dense1 = tf.nn.dropout(dense1, _dropout) # Apply Dropout\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(dense1, _weights['out']), _biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])), \n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])), \n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])), \n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes])) \n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2560, Minibatch Loss= 17023.398438, Training Accuracy= 0.36719\n",
      "Iter 5120, Minibatch Loss= 10436.586914, Training Accuracy= 0.50000\n",
      "Iter 7680, Minibatch Loss= 9447.187500, Training Accuracy= 0.65625\n",
      "Iter 10240, Minibatch Loss= 4775.746094, Training Accuracy= 0.74219\n",
      "Iter 12800, Minibatch Loss= 8045.075195, Training Accuracy= 0.71875\n",
      "Iter 15360, Minibatch Loss= 2367.890869, Training Accuracy= 0.84375\n",
      "Iter 17920, Minibatch Loss= 2176.439209, Training Accuracy= 0.85156\n",
      "Iter 20480, Minibatch Loss= 2778.867676, Training Accuracy= 0.82031\n",
      "Iter 23040, Minibatch Loss= 1966.031860, Training Accuracy= 0.89844\n",
      "Iter 25600, Minibatch Loss= 2016.759033, Training Accuracy= 0.82031\n",
      "Iter 28160, Minibatch Loss= 2252.095215, Training Accuracy= 0.85156\n",
      "Iter 30720, Minibatch Loss= 1345.925293, Training Accuracy= 0.86719\n",
      "Iter 33280, Minibatch Loss= 2039.504150, Training Accuracy= 0.87500\n",
      "Iter 35840, Minibatch Loss= 473.838684, Training Accuracy= 0.93750\n",
      "Iter 38400, Minibatch Loss= 422.729767, Training Accuracy= 0.94531\n",
      "Iter 40960, Minibatch Loss= 2105.120605, Training Accuracy= 0.88281\n",
      "Iter 43520, Minibatch Loss= 570.765747, Training Accuracy= 0.94531\n",
      "Iter 46080, Minibatch Loss= 470.438110, Training Accuracy= 0.96875\n",
      "Iter 48640, Minibatch Loss= 1694.690308, Training Accuracy= 0.89062\n",
      "Iter 51200, Minibatch Loss= 169.557678, Training Accuracy= 0.95312\n",
      "Iter 53760, Minibatch Loss= 415.787811, Training Accuracy= 0.95312\n",
      "Iter 56320, Minibatch Loss= 319.853180, Training Accuracy= 0.96875\n",
      "Iter 58880, Minibatch Loss= 1787.377441, Training Accuracy= 0.89062\n",
      "Iter 61440, Minibatch Loss= 797.861877, Training Accuracy= 0.92969\n",
      "Iter 64000, Minibatch Loss= 1323.999268, Training Accuracy= 0.88281\n",
      "Iter 66560, Minibatch Loss= 1205.812500, Training Accuracy= 0.90625\n",
      "Iter 69120, Minibatch Loss= 820.080811, Training Accuracy= 0.93750\n",
      "Iter 71680, Minibatch Loss= 1021.904541, Training Accuracy= 0.92969\n",
      "Iter 74240, Minibatch Loss= 875.472046, Training Accuracy= 0.90625\n",
      "Iter 76800, Minibatch Loss= 366.891418, Training Accuracy= 0.94531\n",
      "Iter 79360, Minibatch Loss= 709.913269, Training Accuracy= 0.96094\n",
      "Iter 81920, Minibatch Loss= 963.908386, Training Accuracy= 0.93750\n",
      "Iter 84480, Minibatch Loss= 844.870117, Training Accuracy= 0.92188\n",
      "Iter 87040, Minibatch Loss= 1122.324707, Training Accuracy= 0.91406\n",
      "Iter 89600, Minibatch Loss= 545.129517, Training Accuracy= 0.94531\n",
      "Iter 92160, Minibatch Loss= 647.773682, Training Accuracy= 0.94531\n",
      "Iter 94720, Minibatch Loss= 68.103348, Training Accuracy= 0.98438\n",
      "Iter 97280, Minibatch Loss= 983.927979, Training Accuracy= 0.89062\n",
      "Iter 99840, Minibatch Loss= 1064.681396, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.957031\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print \"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: mnist.test.images[:256], \n",
    "                                                             y: mnist.test.labels[:256], \n",
    "                                                             keep_prob: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
